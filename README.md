# LinkedIn Company Employee Scraper

This Python script scrapes LinkedIn for a list of employees from a specific company page. It extracts the person's name, profile URL, designation, and location, then saves the results to a CSV file named `leads.csv`.

This project is for educational purposes only.

## ‚ö†Ô∏è Important Warning
This script is **not** an official API. Scraping LinkedIn is against their Terms of Service, and running this script could lead to your account being restricted or banned. **Use at your own risk.**

## Features
* Fetches the internal Company ID from a public LinkedIn company URL.
* Paginates through employee search results.
* Saves extracted data (Profile Link, Name, Designation, Location) to `leads.csv`.

## ‚öôÔ∏è How to Use

**1. Install Dependencies:**
   You must have Python 3 installed.
   ```bash
   pip install -r requirements.txt

This is a great project to put on GitHub! Uploading it correctly will make it look professional and safe for you to share.

Here is a complete, step-by-step guide on how to upload your script, what to write in the README.md, and the other essential files you need.

üö® CRITICAL SECURITY WARNING üö®
Your script (optimied.py) contains a cookies variable with your personal LinkedIn authentication token (li_at).

DO NOT, under any circumstances, upload this file to a public GitHub repository with that cookie information inside it.

If you do, anyone on the internet can steal your cookie and get full access to your LinkedIn account.

Before you upload, you must delete your cookie from the file and replace it with a placeholder.

Change this: cookies = 'li_rm=AQEJcka...VA0F'

To this: cookies = 'PASTE_YOUR_LINKEDIN_COOKIES_HERE'

## 1. Prepare Your Project Files
Before you upload, you should have four files in your project folder. Your Python file is one; here are the other three.

File 1: README.md (The "front page" of your project)
This is a text file that explains what your project is, how to use it, and any warnings. Create a new file named README.md and paste the text below into it.

File 2: .gitignore (The "ignore" file)
This file tells Git/GitHub not to upload certain files. You do not want to upload your leads.csv output, as this is generated by the script.

File 3: requirements.txt (The "dependencies" list)
This file tells other users what Python libraries they need to install. Your script uses the requests library.

## 2. File Content (Copy and Paste)
Here is the exact content to put into your new files.

File: README.md
Markdown

# LinkedIn Company Employee Scraper

This Python script scrapes LinkedIn for a list of employees from a specific company page. It extracts the person's name, profile URL, designation, and location, then saves the results to a CSV file named `leads.csv`.

This project is for educational purposes only.

## ‚ö†Ô∏è Important Warning
This script is **not** an official API. Scraping LinkedIn is against their Terms of Service, and running this script could lead to your account being restricted or banned. **Use at your own risk.**

## Features
* Fetches the internal Company ID from a public LinkedIn company URL.
* Paginates through employee search results.
* Saves extracted data (Profile Link, Name, Designation, Location) to `leads.csv`.

## ‚öôÔ∏è How to Use

**1. Install Dependencies:**
   You must have Python 3 installed.
   ```bash
   pip install -r requirements.txt

2. Get Your LinkedIn Cookie: This script requires you to be authenticated.

Log in to LinkedIn in your browser (e.g., Chrome).
Open Developer Tools (F12).
Go to the Network tab.
In search box type graphl.
Click on any request to linkedin.com (you may need to refresh the page).
In the "Request Headers" section, find the cookie: field.
Copy the entire value of the cookie.
paste this cookie in scraper.py (where its return PASTE_YOUR_LINKEDIN_COOKIES_HERE)
